{
 "metadata": {
  "name": "",
  "signature": "sha256:5c9373486adeaa180663f629c37b80ee020575b8799e3fcced016279a1b263e1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext watermark"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%watermark -d -v -a 'Sebastian Raschka' -p scikit-learn,nltk,numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sebastian Raschka 12/12/2014 \n",
        "\n",
        "CPython 2.7.8\n",
        "IPython 2.1.0\n",
        "\n",
        "scikit-learn 0.15.2\n",
        "nltk 3.0.0\n",
        "numpy 1.9.1\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font size=\"1.5em\">[More information](https://github.com/rasbt/watermark) about the `watermark` magic command extension.</font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lyrics Mood Classification - Preparing Pickle Classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Reading the dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv('./train_lyrics_1000.csv')\n",
      "df2 = pd.read_csv('./valid_lyrics_200.csv')\n",
      "df = pd.concat([df, df2])\n",
      "df.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>artist</th>\n",
        "      <th>file</th>\n",
        "      <th>genre</th>\n",
        "      <th>lyrics</th>\n",
        "      <th>mood</th>\n",
        "      <th>title</th>\n",
        "      <th>year</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>195</th>\n",
        "      <td>         Prince</td>\n",
        "      <td> TRAKQEA128F1495E21.h5</td>\n",
        "      <td> Rock</td>\n",
        "      <td> {B-side of Glam Slam}\\nSnare drum pounds on th...</td>\n",
        "      <td> happy</td>\n",
        "      <td>            Escape ( LP Version)</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>196</th>\n",
        "      <td>           Cavo</td>\n",
        "      <td> TRAKQLN128F932AC25.h5</td>\n",
        "      <td> Rock</td>\n",
        "      <td> Well I will rise\\nThe morning comes\\nNothing e...</td>\n",
        "      <td>   sad</td>\n",
        "      <td>      Over Again (Album Version)</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>197</th>\n",
        "      <td>            AFI</td>\n",
        "      <td> TRAKQXJ128F147A028.h5</td>\n",
        "      <td> Rock</td>\n",
        "      <td> Listen when I say, when I say it's real\\nReal ...</td>\n",
        "      <td> happy</td>\n",
        "      <td>                  Summer Shudder</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>198</th>\n",
        "      <td>      Vitamin C</td>\n",
        "      <td> TRAKRQW128F427D6E3.h5</td>\n",
        "      <td>  Pop</td>\n",
        "      <td> Imagine a world where the girls, girls rule th...</td>\n",
        "      <td> happy</td>\n",
        "      <td> Girls Against Boys (LP Version)</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>199</th>\n",
        "      <td> Richard Burton</td>\n",
        "      <td> TRAKSRQ128F4269AE8.h5</td>\n",
        "      <td> Jazz</td>\n",
        "      <td> Each evening, from December to December\\nBefor...</td>\n",
        "      <td> happy</td>\n",
        "      <td>                         Camelot</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "             artist                   file genre  \\\n",
        "195          Prince  TRAKQEA128F1495E21.h5  Rock   \n",
        "196            Cavo  TRAKQLN128F932AC25.h5  Rock   \n",
        "197             AFI  TRAKQXJ128F147A028.h5  Rock   \n",
        "198       Vitamin C  TRAKRQW128F427D6E3.h5   Pop   \n",
        "199  Richard Burton  TRAKSRQ128F4269AE8.h5  Jazz   \n",
        "\n",
        "                                                lyrics   mood  \\\n",
        "195  {B-side of Glam Slam}\\nSnare drum pounds on th...  happy   \n",
        "196  Well I will rise\\nThe morning comes\\nNothing e...    sad   \n",
        "197  Listen when I say, when I say it's real\\nReal ...  happy   \n",
        "198  Imagine a world where the girls, girls rule th...  happy   \n",
        "199  Each evening, from December to December\\nBefor...  happy   \n",
        "\n",
        "                               title  year  \n",
        "195             Escape ( LP Version)   NaN  \n",
        "196       Over Again (Album Version)   NaN  \n",
        "197                   Summer Shudder   NaN  \n",
        "198  Girls Against Boys (LP Version)   NaN  \n",
        "199                          Camelot   NaN  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Label Encoder"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import LabelEncoder\n",
      "import numpy as np\n",
      "\n",
      "X_train = df['lyrics'].values \n",
      "y_train = df['mood'].values\n",
      "\n",
      "print('before: %s ...' %y_train[:5])\n",
      "\n",
      "le = LabelEncoder()\n",
      "le.fit(y_train)\n",
      "y_train = le.transform(y_train)\n",
      "\n",
      "print('after: %s ...' %y_train[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "before: ['sad' 'happy' 'sad' 'happy' 'sad'] ...\n",
        "after: [1 0 1 0 1] ...\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Porter Stemmer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Porter Stemmer\n",
      "\n",
      "import nltk\n",
      "import string\n",
      "import re\n",
      "\n",
      "porter_stemmer = nltk.stem.porter.PorterStemmer()\n",
      "\n",
      "def porter_tokenizer(text, stemmer=porter_stemmer):\n",
      "    \"\"\"\n",
      "    A Porter-Stemmer-Tokenizer hybrid to splits sentences into words (tokens) \n",
      "    and applies the porter stemming algorithm to each of the obtained token. \n",
      "    Tokens that are only consisting of punctuation characters are removed as well.\n",
      "    Only tokens that consist of more than one letter are being kept.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "        \n",
      "    text : `str`. \n",
      "      A sentence that is to split into words.\n",
      "        \n",
      "    Returns\n",
      "    ----------\n",
      "    \n",
      "    no_punct : `str`. \n",
      "      A list of tokens after stemming and removing Sentence punctuation patterns.\n",
      "    \n",
      "    \"\"\"\n",
      "    lower_txt = text.lower()\n",
      "    tokens = nltk.wordpunct_tokenize(lower_txt)\n",
      "    stems = [porter_stemmer.stem(t) for t in tokens]\n",
      "    no_punct = [s for s in stems if re.match('^[a-zA-Z]+$', s) is not None]\n",
      "    return no_punct\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Commented out to prevent overwriting files:\n",
      "#\n",
      "# stp = nltk.corpus.stopwords.words('english')\n",
      "# with open('./stopwords_eng.txt', 'w') as outfile:\n",
      "#    outfile.write('\\n'.join(stp))\n",
      "    \n",
      "    \n",
      "with open('./stopwords_eng.txt', 'r') as infile:\n",
      "    stop_words = infile.read().splitlines()\n",
      "print('stop words %s ...' %stop_words[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "stop words ['i', 'me', 'my', 'myself', 'we'] ...\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lyrics Downloader"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib, re\n",
      "import bs4\n",
      "          \n",
      "def songlyrics(artist,title):\n",
      "    artist = urllib.quote(artist.lower().replace(' ','-'))\n",
      "    title = urllib.quote(title.lower().replace(' ','-'))\n",
      "\n",
      "    try:\n",
      "        lyrics = urllib.urlopen(\"http://www.songlyrics.com/%s/%s-lyrics/\" % (artist,title))\n",
      "    except:\n",
      "        return \"Could not connect to songlyrics.com Exiting...\"\n",
      "    text = lyrics.read()\n",
      "    soup = bs4.BeautifulSoup(text)\n",
      "    lyrics = soup.findAll(attrs= {\"id\" : \"songLyricsDiv\"})\n",
      "    if not lyrics:\n",
      "        return \"Lyrics not found.\"\n",
      "    else:\n",
      "        if str(lyrics[0]).startswith('<p class=\"songLyricsV14 iComment-text\" id=\"songLyricsDiv\"></p>'):\n",
      "\n",
      "            return \"Lyrics not found.\"\n",
      "        try:\n",
      "            return re.sub('<[^<]+?>', '', \"\".join(str(lyrics[0])))\n",
      "        except:\n",
      "            return 'Error in parsing the lyrics'\n",
      "        \n",
      "test = songlyrics('Bob Dylan','Blowing in the wind')\n",
      "test = songlyrics('Pharrell', 'happy')\n",
      "test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "\"[Verse 1:]\\r\\nIt might seem crazy what I\\xe2\\x80\\x99m about to say\\r\\nSunshine she\\xe2\\x80\\x99s here, you can take a break\\r\\nI\\xe2\\x80\\x99m a hot air balloon that could go to space\\r\\nWith the air, like I don\\xe2\\x80\\x99t care baby by the way\\n\\r\\n[Chorus:]\\r\\nBecause I\\xe2\\x80\\x99m happy\\r\\nClap along if you feel like a room without a roof\\r\\nBecause I\\xe2\\x80\\x99m happy\\r\\nClap along if you feel like happiness is the truth\\r\\nBecause I\\xe2\\x80\\x99m happy\\r\\nClap along if you know what happiness is to you\\r\\nBecause I\\xe2\\x80\\x99m happy\\r\\nClap along if you feel like that\\xe2\\x80\\x99s what you wanna do\\n\\r\\n[Verse 2:]\\r\\nHere come bad news talking this and that, yeah,\\r\\nWell, give me all you got, and don\\xe2\\x80\\x99t hold it back, yeah,\\r\\nWell, I should probably warn you I\\xe2\\x80\\x99ll be just fine, yeah,\\r\\nNo offense to you, don\\xe2\\x80\\x99t waste your time\\r\\nHere\\xe2\\x80\\x99s why\\n\\r\\n[Chorus]\\n\\r\\nHey, come on\\n\\r\\n[Bridge:]\\r\\n(happy)\\r\\nBring me down\\r\\nCan't nothing bring me down\\r\\nMy level's too high\\r\\nBring me down\\r\\nCan't nothing bring me down\\r\\nI said (let me tell you now)\\r\\nBring me down\\r\\nCan't nothing bring me down\\r\\nMy level's too high\\r\\nBring me down\\r\\nCan't nothing bring me down\\r\\nI said\\n\\r\\n[Chorus 2x]\\n\\r\\nHey, come on\\n\\r\\n(happy)\\r\\nBring me down\\xe2\\x80\\xa6 can\\xe2\\x80\\x99t nothing\\xe2\\x80\\xa6\\r\\nBring me down\\xe2\\x80\\xa6 my level's too high\\xe2\\x80\\xa6\\r\\nBring me down\\xe2\\x80\\xa6 can\\xe2\\x80\\x99t nothing\\xe2\\x80\\xa6\\r\\nBring me down, I said (let me tell you now)\\n\\r\\n[Chorus 2x]\\n\\r\\nCome on\""
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vectorizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "import re\n",
      "\"\"\"\n",
      "countv = CountVectorizer(\n",
      "                  binary=False,\n",
      "                  decode_error=\"replace\",\n",
      "                  stop_words=stop_words,\n",
      "                  preprocessor=lambda text: re.sub('[^a-zA-Z]', ' ', text.lower()),\n",
      "                  ngram_range=(1,1),\n",
      "                  tokenizer=lambda text: text.split()\n",
      "                )\n",
      "\"\"\"\n",
      "countv = CountVectorizer(\n",
      "                  binary=False,\n",
      "                  decode_error=\"replace\",\n",
      "                  stop_words=stop_words,\n",
      "                  ngram_range=(1,1),\n",
      "\n",
      "                )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countv = countv.fit(X_train)\n",
      "X_train_countv = countv.transform(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#joblib.dump(tfidf, './lyrics_tfidf_jb.pkl') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "clf_countv = MultinomialNB(alpha=1.0, fit_prior=False)\n",
      "clf_countv = clf_countv.fit(X_train_countv, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test\n",
      "x = songlyrics('Pharrell', 'happy')\n",
      "x_countv = countv.transform([x])\n",
      "\n",
      "le.inverse_transform(clf_countv.predict(x_countv))\n",
      "clf_countv.predict_proba(x_countv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array([[  9.99990615e-01,   9.38515448e-06]])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%matplotlib inline\n",
      "#import matplotlib.pyplot as plt\n",
      "#import seaborn as sns\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "#import matplotlib as mpl\n",
      "\n",
      "cm = metrics.confusion_matrix(y_train, clf_countv.predict(X_train_countv))\n",
      "\n",
      "print(cm)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[533  18]\n",
        " [ 37 612]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import shelve\n",
      "import dill\n",
      "\n",
      "d = shelve.open('countv_clf')\n",
      "\n",
      "d['label_encoder'] = le\n",
      "d['lyrics_countv'] = countv\n",
      "d['lyrics_clf'] = clf_countv\n",
      "d.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import dill\n",
      "\n",
      "\n",
      "try:\n",
      "    d = open('label_encoder.p', 'wb')\n",
      "    dill.dump(le, d)\n",
      "finally:\n",
      "    d.close()\n",
      "    \n",
      "    \n",
      "try:\n",
      "    d = open('countv.p', 'wb')\n",
      "    dill.dump(countv, d)\n",
      "finally:\n",
      "    d.close()   \n",
      "\n",
      "try:\n",
      "    d = open('clf_countv.p', 'wb')\n",
      "    dill.dump(clf_countv, d)\n",
      "finally:\n",
      "    d.close()  \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "\n",
      "try:\n",
      "    d = open('label_encoder.p', 'wb')\n",
      "    pickle.dump(le, d)\n",
      "finally:\n",
      "    d.close()\n",
      "    \n",
      "    \n",
      "try:\n",
      "    d = open('countv.p', 'wb')\n",
      "    pickle.dump(countv, d)\n",
      "finally:\n",
      "    d.close()   \n",
      "\n",
      "try:\n",
      "    d = open('clf_countv.p', 'wb')\n",
      "    pickle.dump(clf_countv, d)\n",
      "finally:\n",
      "    d.close() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import shelve\n",
      "import re\n",
      "\n",
      "\n",
      "d = shelve.open('countv_clf.db', 'r')\n",
      "\n",
      "def preprocess(text):\n",
      "    return re.sub('[^a-zA-Z]', ' ', text.lower())\n",
      "\n",
      "def tokenize(text):\n",
      "    return text.split()\n",
      "\n",
      "le = d['label_encoder']\n",
      "countv = d['lyrics_countv']\n",
      "clf = d['lyrics_clf'] \n",
      "\n",
      "d.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print number of mood labels\n",
      "import dill\n",
      "\n",
      "le = dill.load(open('label_encoder.p'))\n",
      "countv = dill.load(open('countv.p'))\n",
      "clf_countv = dill.load(open('clf_countv.p'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_countv = countv.transform([songlyrics('Bob Dylan', 'blowin in the wind')])\n",
      "pred = clf.predict(x_countv)[0]\n",
      "label = le.inverse_transform(pred)\n",
      "label = 'Prediction: %s' % label\n",
      "            \n",
      "proba = clf.predict_proba(x_countv).ravel()[pred]\n",
      "proba = round(proba*100)\n",
      "proba = 'probability %.2f%% ' % (proba)\n",
      "proba\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'songlyrics' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-eba4e5137ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_countv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msonglyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bob Dylan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blowin in the wind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_countv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Prediction: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'songlyrics' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}